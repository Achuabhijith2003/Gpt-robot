import google.generativeai as genai

def gpt_response(prompt):
  """Generates a response using the generativeai library with safety settings.

  Args:
      prompt: The user's input prompt for the chatbot.

  Returns:
      The response generated by the Gemini-1.0-pro model.
  """

  # API Key Configuration (Replace with your actual API key)
  API_KEY = "AIzaSyClZFTc5kyUjvJYf5AO7FgYYPRLkTF4eAM"
  genai.configure(api_key=API_KEY)

  # Model Configuration
  generation_config = {
      "temperature": 0.9,  # Controls randomness in responses
      "top_p": 1,          # Focuses generation on high probability tokens
      "top_k": 1,          # Limits considered tokens at each step
      "max_output_tokens": 2048,  # Maximum length of generated text
  }

  safety_settings = [
      {
          "category": "HARM_CATEGORY_HARASSMENT",
          "threshold": "BLOCK_MEDIUM_AND_ABOVE"
      },
      {
          "category": "HARM_CATEGORY_HATE_SPEECH",
          "threshold": "BLOCK_MEDIUM_AND_ABOVE"
      },
      {
          "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
          "threshold": "BLOCK_MEDIUM_AND_ABOVE"
      },
      {
          "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
          "threshold": "BLOCK_MEDIUM_AND_ABOVE"
      },
  ]

  # Create the GenerativeModel Instance with Safety Measures
  model = genai.GenerativeModel(
      model_name="gemini-1.0-pro",
      generation_config=generation_config,
      safety_settings=safety_settings
  )

  # Start a Conversation (Optional for Multi-Turn Interactions)
  convo = model.start_chat(history=[])  # Empty history for new conversation

  # Send the User's Prompt and Return the Model's Response
  response = convo.send_message(prompt)
  return response.text

# Example Usage
user_prompt = "What is the weather like today?"
generated_response = gpt_response(user_prompt)
print(generated_response)
